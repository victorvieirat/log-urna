{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/13 12:45:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession \n",
    "\n",
    "sc = SparkSession.builder.appName(\"DataFrame\").getOrCreate()#.setSystemProperty(\"spark.executor.memory\", \"4g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_interesse = [\n",
    "    \"Eleitor foi habilitado\",\n",
    "    \"Voto confirmado para [Deputado Federal]\",\n",
    "    \"Voto confirmado para [Deputado Estadual]\",\n",
    "    \"Voto confirmado para [Senador]\",\n",
    "    \"Voto confirmado para [Governador]\",\n",
    "    \"Voto confirmado para [Presidente]\",\n",
    "    \"Tecla indevida pressionada\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+----------------------------------------+\n",
      "|_c0                |_c2     |_c4                                     |\n",
      "+-------------------+--------+----------------------------------------+\n",
      "|2022-10-02 08:03:26|67305985|Eleitor foi habilitado                  |\n",
      "|2022-10-02 08:03:48|67305985|Voto confirmado para [Deputado Federal] |\n",
      "|2022-10-02 08:03:58|67305985|Voto confirmado para [Deputado Estadual]|\n",
      "|2022-10-02 08:04:37|67305985|Voto confirmado para [Senador]          |\n",
      "|2022-10-02 08:04:42|67305985|Voto confirmado para [Governador]       |\n",
      "|2022-10-02 08:04:47|67305985|Voto confirmado para [Presidente]       |\n",
      "|2022-10-02 08:06:26|67305985|Eleitor foi habilitado                  |\n",
      "|2022-10-02 08:06:58|67305985|Voto confirmado para [Deputado Federal] |\n",
      "|2022-10-02 08:07:19|67305985|Voto confirmado para [Deputado Estadual]|\n",
      "|2022-10-02 08:07:25|67305985|Tecla indevida pressionada              |\n",
      "+-------------------+--------+----------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import to_date\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "DATA_PATH = \"/app/data/\"\n",
    "input_file = DATA_PATH+\"texto/*\" \n",
    "\n",
    "\n",
    "df = sc.read.csv(input_file, sep=\"\\t\", header=False)\n",
    "df = df.drop(\"_c1\",\"_c3\",\"_c5\")\n",
    "df =  df.filter(col(\"_c4\").isin(logs_interesse))\n",
    "df = df.withColumn(\"_c0\", F.to_timestamp(col(\"_c0\"), 'dd/MM/yyyy HH:mm:ss'))\n",
    "\n",
    "df.show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1119794"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 59:========================================>               (13 + 5) / 18]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|                 _c4| count|\n",
      "+--------------------+------+\n",
      "|Tecla indevida pr...|239991|\n",
      "|Solicita digital....|232247|\n",
      "|Capturada a digit...|223653|\n",
      "|Aguardando digita...|139922|\n",
      "|Título digitado p...|135910|\n",
      "|Digital capturada...|126345|\n",
      "|Eleitor foi habil...|125834|\n",
      "|Número de tentati...|125790|\n",
      "|O voto do eleitor...|125729|\n",
      "|Voto confirmado p...|125718|\n",
      "|Voto confirmado p...|125683|\n",
      "|Voto confirmado p...|125623|\n",
      "|Voto confirmado p...|125611|\n",
      "|Voto confirmado p...|125605|\n",
      "|Tipo de habilitaç...| 97859|\n",
      "|Batimento de digi...| 75409|\n",
      "|Verificação de as...| 73218|\n",
      "|Dedo reconhecido ...| 49359|\n",
      "|Biometria coletad...| 40606|\n",
      "|Dedo reconhecido ...| 34668|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 28 ms, sys: 10.4 ms, total: 38.3 ms\n",
      "Wall time: 6.11 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#unique_values = df.select(\"_c4\").distinct().orderBy(\"_c4\")\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "unique_values =  df.select(\"_c4\").withColumn(\"_c4\", regexp_replace(df[\"_c4\"], r\"\\d+\", \"\")).groupBy(\"_c4\").count().sort(\"count\", ascending=False)\n",
    "#write as csv\n",
    "unique_values.write.mode(\"overwrite\").csv(DATA_PATH+\"unique_values\")\n",
    "#unique_values.write.mode(\"overwrite\").text(DATA_PATH+\"unique_values\")\n",
    "\n",
    "# Show the unique values\n",
    "unique_values.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
